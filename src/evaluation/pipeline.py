import os
import re
import random
import pandas as pd
from typing import Tuple, Dict, Any

from src.config import DATA_PATH, USE_S3, configure_mlflow, logger
from src.storage.io import Storage
from src.data.data_loader import load_data_for_prediction
from src.predict.pipeline import predict_for_userId
from src.train.core import load_model_from_mlflow


def explode_history(df: pd.DataFrame) -> pd.DataFrame:
    """
    Converte a coluna 'history' (contendo strings com pageIds colados)
    em m√∫ltiplas linhas, extraindo os valores entre aspas simples.

    Exemplo de entrada:
      "['be89a7da-d9fa-49d4-9fdc-388c27a15bc8'\n '01c59ff6-fb82-4258-918f-2910cb2d4c52']"

    Returns:
        pd.DataFrame: DataFrame com a coluna 'history' explodida e renomeada para 'pageId'.
    """

    def parse_history_str(s: str) -> list:
        s = s.strip().replace("[", "").replace("]", "")
        tokens = re.findall(r"'([^']+)'", s)
        return tokens

    df["history"] = df["history"].apply(
        lambda x: parse_history_str(x) if isinstance(x, str) else x
    )
    df_exploded = df.explode("history").reset_index(drop=True)
    df_exploded.rename(columns={"history": "pageId"}, inplace=True)
    return df_exploded


def evaluate_model(
    model: Any, n: int = 5, score_threshold: float = 15, sample_size: int = 5
) -> Tuple[Dict[str, Any], Dict[str, Any]]:
    """
    Avalia o modelo nos dados de valida√ß√£o.

    O fluxo realiza:
      1. Leitura do CSV de valida√ß√£o.
      2. Explos√£o da coluna 'history' para obter os pageIds consumidos (ground truth).
      3. Agrupamento por usu√°rio para coletar o conjunto de pageIds consumidos.
      4. Carregamento dos DataFrames de predi√ß√£o (features de not√≠cias e clientes).
      5. Para cada usu√°rio (amostrado, se sample_size for definido), gera recomenda√ß√µes
         e verifica se h√° pelo menos um acerto (hit rate).

    Args:
        model: Modelo treinado para predi√ß√£o.
        n (int, optional): N√∫mero m√°ximo de recomenda√ß√µes por usu√°rio. Default: 5.
        score_threshold (float, optional): Score m√≠nimo para considerar uma recomenda√ß√£o.
        Default: 15.
        sample_size (int, optional): Se definido, avalia apenas essa quantidade de usu√°rios.

    Returns:
        Tuple[Dict[str, Any], Dict[str, Any]]:
            - M√©tricas agregadas (total de usu√°rios avaliados, hits e hit_rate).
            - Detalhes por usu√°rio (ground truth, recomenda√ß√µes e flag de hit).
    """
    storage = Storage(use_s3=USE_S3)
    validation_csv_path = os.path.join(
        DATA_PATH, "challenge-webmedia-e-globo-2023/val_data/validacao.csv"
    )
    val_df = storage.read_csv(validation_csv_path)
    logger.info("üîç [Evaluation] Dados de valida√ß√£o carregados: %s", val_df.shape)

    # Explode a coluna 'history' para obter os pageIds consumidos
    val_exploded = explode_history(val_df)
    logger.info("üîç [Evaluation] Dados de valida√ß√£o explodidos: %s", val_exploded.shape)

    # Agrupa por usu√°rio para formar o ground truth
    ground_truth = val_exploded.groupby("userId")["pageId"].apply(set).to_dict()
    logger.info("üîç [Evaluation] N√∫mero de usu√°rios no ground truth: %d", len(ground_truth))

    # Amostra os usu√°rios para acelerar a avalia√ß√£o, se sample_size for especificado
    if sample_size and sample_size < len(ground_truth):
        all_users = list(ground_truth.keys())
        sampled_users = random.sample(all_users, sample_size)
        ground_truth = {user: ground_truth[user] for user in sampled_users}
        logger.info("üîç [Evaluation] Amostrando ground truth para %d usu√°rios.", sample_size)

    # Carrega os DataFrames de predi√ß√£o
    pred_data = load_data_for_prediction(storage, include_metadata=False)
    news_features_df = pred_data["news_features"]
    clients_features_df = pred_data["clients_features"]

    hits = 0
    total_users = 0
    details = {}

    # Para cada usu√°rio, gera recomenda√ß√µes e verifica se h√° acerto
    for user, true_page_ids in ground_truth.items():
        recs, is_cold_start = predict_for_userId(
            user,
            clients_features_df,
            news_features_df,
            model,
            n=n,
            score_threshold=score_threshold,
        )
        rec_page_ids = {rec["pageId"] for rec in recs}
        hit = len(true_page_ids.intersection(rec_page_ids)) > 0
        if hit:
            hits += 1
        total_users += 1
        details[user] = {
            "ground_truth": true_page_ids,
            "recommendations": rec_page_ids,
            "hit": hit,
        }

    hit_rate = hits / total_users if total_users > 0 else 0.0
    metrics = {"total_users": total_users, "hits": hits, "hit_rate": hit_rate}
    return metrics, details


if __name__ == "__main__":
    configure_mlflow()
    model = load_model_from_mlflow()
    if model is None:
        logger.error("Modelo n√£o carregado. Verifique os logs do MLflow.")
        raise SystemExit("Encerrando avalia√ß√£o, modelo n√£o dispon√≠vel.")

    metrics, details = evaluate_model(model, n=5, score_threshold=15)
    logger.info("M√©tricas de avalia√ß√£o: %s", metrics)
    print("M√©tricas de avalia√ß√£o:", metrics)
