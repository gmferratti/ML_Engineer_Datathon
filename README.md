# ML_Engineer_Datathon

[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/)

√öltimo desafio FIAP para a conclus√£o da p√≥s em Machine Learning Engineering.

---

## Objetivo

Desenvolver um sistema de recomenda√ß√£o personalizado baseado no consumo de not√≠cias do G1, com o objetivo de prever qual ser√° a pr√≥xima not√≠cia lida por um usu√°rio. O sistema √© capaz de lidar com diversos perfis de usu√°rios ‚Äì desde aqueles com amplo hist√≥rico de consumo at√© os que est√£o acessando o site pela primeira vez (cold start).

---

## Integrantes

- Antonio Eduardo de Oliveira Lima
- Gustavo Mendon√ßa Ferratti
- Luiz Claudio Santana Barbosa
- Mauricio de Araujo Pintor
- Rodolfo Olivieri

---

## Vis√£o Geral do Projeto

O projeto ML_Engineer_Datathon √© composto por v√°rios m√≥dulos que, juntos, formam um sistema completo de recomenda√ß√£o. Cada m√≥dulo possui sua pr√≥pria documenta√ß√£o detalhada e √© respons√°vel por uma parte espec√≠fica do fluxo. Os m√≥dulos principais s√£o:

- **Feature Engineering:**  
  Processa os dados brutos (not√≠cias e usu√°rios), extrai e transforma as features e calcula o score de engajamento (TARGET).

- **Treinamento e Ranking:**  
  Utiliza o **LightGBMRanker** ‚Äì um modelo de ranking baseado no LightGBM com o objetivo **lambdarank** ‚Äì para treinar o modelo e gerar uma ordena√ß√£o dos itens. O treinamento otimiza m√©tricas de ranking, como o NDCG.

- **API de Predi√ß√£o:**  
  Disponibiliza uma API (via FastAPI) para realizar predi√ß√µes em tempo real. A API carrega os dados pr√©-processados e o modelo treinado, trata os inputs (inclusive para casos de cold start) e retorna as recomenda√ß√µes ordenadas com metadados.

- **Avalia√ß√£o:**  
  Um pipeline de avalia√ß√£o utiliza a m√©trica **NDCG@10** para medir a qualidade do ranking gerado pelo modelo, comparando os scores preditos com os valores reais de engajamento.

---

## Fluxo Geral

1. **Pr√©-processamento dos Dados:**  
   - **Not√≠cias:** Concatena√ß√£o, filtragem e extra√ß√£o de informa√ß√µes (localidade, temas, data/hora de publica√ß√£o).
   - **Usu√°rios:** Processamento de hist√≥ricos, extra√ß√£o de features temporais e defini√ß√£o da flag `coldStart`.
   - **Mix de Features:** Combina√ß√£o dos dados de not√≠cias e usu√°rios, c√°lculo de gaps temporais e propor√ß√µes por categoria.
   - **C√°lculo do TARGET:** C√°lculo do score de engajamento usando m√©tricas como cliques, tempo na p√°gina, scroll, rec√™ncia, tamanho do hist√≥rico e gap temporal.  
     
     A f√≥rmula geral √©:
     ```
     scoreBase = numberOfClicksHistory 
                 + 1.5 * (timeOnPageHistory / 1000)
                 + scrollPercentageHistory 
                 - (minutesSinceLastVisit / 60)
     ```
     Em seguida:
     ```
     rawScore = scoreBase * (historySize / 130) * (1 / (1 + (timeGapDays / 50)))
     ```
     Valores negativos s√£o ajustados para zero, aplicando `log1p`, escalonamento via Min-Max Scaling e arredondamento para gerar o TARGET final.

2. **Treinamento e Ranking:**  
   - O **LightGBMRanker** √© treinado com os dados processados utilizando o objetivo **lambdarank**, que otimiza a ordena√ß√£o dos itens com base em m√©tricas de ranking como o NDCG.
   - Durante a predi√ß√£o, as features dos clientes e das not√≠cias s√£o combinadas para gerar scores, que determinam a ordem dos itens recomendados.

3. **API de Predi√ß√£o:**  
   - A API, desenvolvida com FastAPI, recebe requisi√ß√µes contendo par√¢metros como `userId`, `max_results` e `minScore`.
   - Caso o usu√°rio n√£o seja encontrado (indicando cold start), a API retorna as not√≠cias mais recentes com score definido como "desconhecido", juntamente com metadados (t√≠tulo, URL, issuedDate e issuedTime).
   - Caso o usu√°rio possua hist√≥rico, o modelo gera scores que determinam o ranking final das not√≠cias.

4. **Avalia√ß√£o:**  
   - Um pipeline de avalia√ß√£o calcula o **NDCG@10** para medir a qualidade do ranking.  
     - **NDCG@10:** √â uma m√©trica que avalia a ordena√ß√£o dos itens. Um valor de 1 indica uma ordena√ß√£o perfeita, enquanto valores pr√≥ximos de 0 indicam uma ordena√ß√£o ruim.

---

## Configura√ß√£o Inicial e Ambiente

- **Principais Comandos:**  
  Todos os comandos principais para executar os m√≥dulos do projeto est√£o definidos no **Makefile**. Consulte o Makefile para comandos como:
  - `make evaluate`
  - `make predict`
  - `make train`
  - Entre outros.

- **Vari√°veis de Ambiente:**  
  √â necess√°rio criar um arquivo `.env` na raiz do projeto com, pelo menos, a seguinte vari√°vel:
```
  ENV = "dev"
```
Os valores poss√≠veis para `ENV` s√£o `"dev"`, `"staging"` ou `"prod"`.

- **Credenciais e Servidores:**  
- **Azure:** Certifique-se de configurar as credenciais da Azure no arquivo `.env` para acesso aos recursos necess√°rios.
- **MLflow:** Inicie o servidor do MLflow (por exemplo, via `mlflow ui`) com a URI configurada (ex.: `http://localhost:5001`).
- **API:** Inicie a API utilizando o comando especificado no Makefile (por exemplo, via `uvicorn`).

---

## Empacotamento e Deploy

Ap√≥s a finaliza√ß√£o do desenvolvimento e testes, o sistema √© empacotado utilizando Docker e passa por etapas de valida√ß√£o e deploy. Detalhes sobre o empacotamento e deploy est√£o documentados nos respectivos READMEs dos m√≥dulos de API e Docker.

---

## Refer√™ncias e Documenta√ß√£o Complementar

Para obter mais informa√ß√µes sobre cada etapa do projeto, consulte os READMEs espec√≠ficos dos m√≥dulos:

- **Feature Engineering:** Documenta√ß√£o em `README_data_loader.md` e outros arquivos de pr√©-processamento.
- **Treinamento e Ranking:** Documenta√ß√£o em `README_ranker.md`.
- **API de Predi√ß√£o:** Documenta√ß√£o em `README_app.md`.
- **Avalia√ß√£o:** Documenta√ß√£o em `README_predict.md`.

Outras refer√™ncias importantes:
- [LightGBM Documentation](https://lightgbm.readthedocs.io/)
- [Lambdarank Paper](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf)
- [MLflow Model Registry](https://mlflow.org/docs/latest/model-registry.html)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)

---

Este README.md global oferece uma vis√£o integrada do projeto ML_Engineer_Datathon, resumindo as principais etapas, m√≥dulos e configura√ß√µes necess√°rias para a execu√ß√£o e deploy do sistema. Para detalhes espec√≠ficos de cada componente, consulte os READMEs individuais dispon√≠veis em cada pasta do projeto.


# Setups e Rodagens em Containers


## ‚ú® Principais Caracter√≠sticas

- **API FastAPI:** Interface de alta performance para recomenda√ß√µes em tempo real
- **MLflow Integration:** Registro e versionamento de modelos com tracking de m√©tricas
- **Containeriza√ß√£o:** Deploy simplificado via Docker
- **Otimiza√ß√µes de Performance:** Caching, profiling e redu√ß√£o de processamento redundante
- **Suporte a Ambientes:** Configura√ß√µes para desenvolvimento local e produ√ß√£o
- **Suporte a Cold Start:** Tratamento para usu√°rios novos ou com pouca informa√ß√£o
- **Portabilidade AWS:** Pronto para deploy em AWS ECS Fargate

## üöÄ Inicializa√ß√£o R√°pida

### Pr√©-requisitos

- Docker
- Docker Compose
- Bash (para o script de inicializa√ß√£o)

### Executar Localmente (Desenvolvimento)

```bash
# Tornar o script execut√°vel
chmod +x run-local.sh

# Iniciar todos os servi√ßos em modo desenvolvimento (API + MLflow)
./run-local.sh

# Para reconstruir as imagens (ap√≥s altera√ß√µes no c√≥digo)
./run-local.sh dev full rebuild

# Para ver logs ap√≥s inicializa√ß√£o
./run-local.sh dev full logs
```

### Executar em Modo Produ√ß√£o (Usando MLflow remoto)

```bash
# Configurar credenciais AWS para acesso ao S3 (opcional)
export AWS_ACCESS_KEY_ID="sua-chave"  
export AWS_SECRET_ACCESS_KEY="seu-secret"

# Iniciar apenas a API em modo produ√ß√£o
./run-local.sh prod api
```

### Op√ß√µes de Inicializa√ß√£o

```bash
# Ver ajuda e todas as op√ß√µes dispon√≠veis
./run-local.sh help

# Exemplos comuns:
./run-local.sh dev api      # Apenas API em modo desenvolvimento
./run-local.sh dev mlflow   # Apenas MLflow local
./run-local.sh prod api     # API em modo produ√ß√£o (MLflow remoto)
```

## üèóÔ∏è Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ Dockerfile              # Configura√ß√£o de container otimizado
‚îú‚îÄ‚îÄ docker-compose.yml      # Orquestra√ß√£o de servi√ßos Docker
‚îú‚îÄ‚îÄ run-local.sh            # Script de inicializa√ß√£o simplificada
‚îú‚îÄ‚îÄ DEPLOY_AWS.md           # Instru√ß√µes para deploy na AWS
‚îú‚îÄ‚îÄ pyproject.toml          # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ configs/                # Configura√ß√µes de ambiente
‚îî‚îÄ‚îÄ src/                    # C√≥digo-fonte
    ‚îú‚îÄ‚îÄ api/                # API de recomenda√ß√£o
    ‚îú‚îÄ‚îÄ data/               # Manipula√ß√£o de dados
    ‚îú‚îÄ‚îÄ evaluation/         # M√©tricas e avalia√ß√£o
    ‚îú‚îÄ‚îÄ features/           # Feature engineering
    ‚îú‚îÄ‚îÄ predict/            # Pipeline de predi√ß√£o
    ‚îú‚îÄ‚îÄ recommendation_model/# Modelos de recomenda√ß√£o
    ‚îú‚îÄ‚îÄ storage/            # Abstra√ß√£o de armazenamento
    ‚îî‚îÄ‚îÄ train/              # Pipeline de treinamento
```

## üîç Endpoints da API

- **`GET /health`**: Verifica a sa√∫de da API
- **`GET /info`**: Informa√ß√µes sobre o modelo e ambiente
- **`POST /predict`**: Gera recomenda√ß√µes para um usu√°rio

### Exemplo de requisi√ß√£o para `/predict`:

```json
{
  "userId": "4b3c2c5c0edaf59137e164ef6f7d88f94d66d0890d56020de1ca6afd55b4f297",
  "max_results": 5,
  "minScore": 0.3
}
```

## üìä Monitoramento de Performance

A API agora inclui m√©tricas detalhadas de performance para ajudar a identificar e resolver gargalos. Ao fazer uma chamada para `/predict`, a resposta incluir√°:

```json
{
  "processing_time_ms": 123.45,
  "timing_details": {
    "dependencies": 0.01,
    "prediction": 0.12,
    "formatting": 0.01,
    "total_ms": 123.45
  }
}
```

## üê≥ Configura√ß√£o Docker

O projeto utiliza dois arquivos principais:

- **`Dockerfile`**: Container otimizado para produ√ß√£o
- **`docker-compose.yml`**: Configura√ß√£o de ambiente local

## üåê Configura√ß√£o de Ambientes

O sistema suporta dois ambientes principais:

### 1. Desenvolvimento (`dev`)

- MLflow local para experimentos
- Armazenamento local de dados
- Taxa de amostragem reduzida para testes r√°pidos

### 2. Produ√ß√£o (`prod`)

- MLflow remoto para registro de modelos
- Armazenamento S3 para dados e artefatos
- Taxa de amostragem completa para melhor performance


## üö¢ Deploy na AWS

Para fazer o deploy do sistema na AWS ECS usando Fargate:

1. Siga as instru√ß√µes detalhadas em `DEPLOY_AWS.md`
2. Automatize o processo com o script de deploy inclu√≠do


## üìö Documenta√ß√£o Adicional

- **`DEPLOY_AWS.md`**: Instru√ß√µes para deploy na AWS
- Para mais detalhes sobre o MLflow, visite a [documenta√ß√£o oficial](https://mlflow.org/docs/latest/index.html)

## ü§ù Contribuindo

Para contribuir com o projeto:

1. Clone o reposit√≥rio
2. Instale as depend√™ncias com `uv pip install -e .`
3. Crie uma nova branch para suas altera√ß√µes
4. Envie um Pull Request com uma descri√ß√£o clara das mudan√ßas

## üìù Notas

- O script `run-local.sh` deve ser executado do diret√≥rio raiz do projeto