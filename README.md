# ML_Engineer_Datathon

[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/)

Este documento est√° localizado em **docs/** e reflete a estrutura do projeto, que espelha a organiza√ß√£o dos m√≥dulos contidos na pasta *src/*.

---

## √çndice

1. [Objetivo e Contexto](#objetivo-e-contexto)
2. [Vis√£o Geral do Projeto](#vis√£o-geral-do-projeto)
3. [Fluxo de Execu√ß√£o](#fluxo-de-execu√ß√£o)
4. [Configura√ß√£o e Ambiente](#configura√ß√£o-e-ambiente)
5. [Empacotamento e Deploy](#empacotamento-e-deploy)
6. [Estrutura do Projeto](#estrutura-do-projeto)
7. [Endpoints e Monitoramento](#endpoints-e-monitoramento)
8. [Contribui√ß√£o e Notas](#contribui√ß√£o-e-notas)
9. [Refer√™ncias](#refer√™ncias)

---

## Objetivo e Contexto

Desenvolver um sistema de recomenda√ß√£o personalizado, com foco em prever a pr√≥xima not√≠cia a ser lida por um usu√°rio com base no consumo de not√≠cias do G1. O sistema √© projetado para lidar tanto com usu√°rios com hist√≥rico consolidado quanto com aqueles em situa√ß√£o de *cold start*.

**Integrantes:**

- Antonio Eduardo de Oliveira Lima
- Gustavo Mendon√ßa Ferratti
- Luiz Claudio Santana Barbosa
- Mauricio de Araujo Pintor
- Rodolfo Olivieri

---

## Vis√£o Geral do Projeto

O ML_Engineer_Datathon √© composto por diversos m√≥dulos que, integrados, formam um sistema completo de recomenda√ß√£o. Cada m√≥dulo possui documenta√ß√£o espec√≠fica, mas aqui apresentamos um resumo dos principais componentes:

- **Feature Engineering:**  
  Processamento dos dados brutos de not√≠cias e usu√°rios, extra√ß√£o e transforma√ß√£o de features e c√°lculo do score de engajamento (TARGET).

- **Treinamento e Ranking:**  
  Utiliza√ß√£o do **LightGBMRanker** com o objetivo *lambdarank* para treinar o modelo e gerar a ordena√ß√£o dos itens, otimizando m√©tricas como o NDCG.

- **API de Predi√ß√£o:**  
  Implementada com FastAPI, esta API processa os inputs, trata casos de *cold start* e retorna recomenda√ß√µes ordenadas com os metadados relevantes.

- **Avalia√ß√£o:**  
  Pipeline que utiliza a m√©trica **NDCG@10** para mensurar a qualidade do ranking gerado pelo modelo.

---

## Fluxo de Execu√ß√£o

1. **Pr√©-processamento dos Dados:**  
   - **Not√≠cias:** Consolida√ß√£o, filtragem e extra√ß√£o de informa√ß√µes (localidade, temas, data/hora).  
   - **Usu√°rios:** Processamento de hist√≥ricos, extra√ß√£o de features temporais e identifica√ß√£o de *cold start*.  
   - **Integra√ß√£o:** Combina√ß√£o dos dados e c√°lculo do TARGET com base em cliques, tempo na p√°gina, scroll, rec√™ncia e outras vari√°veis.  
     
     A f√≥rmula utilizada √©:

     ```
     scoreBase = numberOfClicksHistory 
                 + 1.5 * (timeOnPageHistory / 1000)
                 + scrollPercentageHistory 
                 - (minutesSinceLastVisit / 60)
     ```
     
     Em seguida:
     
     ```
     rawScore = scoreBase * (historySize / 130) * (1 / (1 + (timeGapDays / 50)))
     ```
     
     Valores negativos s√£o ajustados, aplicando transforma√ß√µes como `log1p` e escalonamento via Min-Max Scaling.

2. **Treinamento e Gera√ß√£o de Ranking:**  
   - O modelo **LightGBMRanker** √© treinado para otimizar a ordena√ß√£o dos itens com base no NDCG.
   - Durante a predi√ß√£o, as features s√£o combinadas para definir a ordem das recomenda√ß√µes.

3. **API de Predi√ß√£o:**  
   - A API processa requisi√ß√µes, tratando os inputs e gerando respostas diferenciadas para casos de *cold start* ou hist√≥rico de consumo consolidado.

4. **Avalia√ß√£o:**  
   - Um pipeline calcula o **NDCG@10** para medir a efic√°cia do ranking gerado, permitindo ajustes e melhorias cont√≠nuas.

---

## Configura√ß√£o e Ambiente

### Principais Comandos

Todos os comandos para execu√ß√£o dos m√≥dulos est√£o definidos no **Makefile**. Entre eles:

- `make evaluate`
- `make predict`
- `make train`
- Entre outros.

### Vari√°veis de Ambiente

Crie um arquivo `.env` na raiz do projeto contendo, no m√≠nimo:

```
ENV="dev"
```


Os poss√≠veis valores para `ENV` s√£o `"dev"`, `"staging"` ou `"prod"`.

### Credenciais e Servidores

- **Azure:** Configure as credenciais necess√°rias no `.env` para acesso aos recursos.
- **MLflow:** Inicie o servidor do MLflow (por exemplo, com `mlflow ui`) utilizando a URI apropriada.
- **API:** Execute a API conforme especificado no Makefile (por exemplo, via `uvicorn`).

---

## Empacotamento e Deploy

Ap√≥s testes e valida√ß√£o, o sistema √© empacotado com Docker e passa por um rigoroso processo de deploy:

- **Docker:**  
  - **Dockerfile:** Define o container otimizado para produ√ß√£o.
  - **docker-compose.yml:** Orquestra os servi√ßos para ambiente local.

- **Deploy:**  
  Documenta√ß√£o adicional sobre o deploy est√° dispon√≠vel em `DEPLOY_AWS.md`, que detalha o processo para a AWS utilizando ECS Fargate.

---

## üèóÔ∏è Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ Dockerfile              # Configura√ß√£o de container otimizado
‚îú‚îÄ‚îÄ docker-compose.yml      # Orquestra√ß√£o de servi√ßos Docker
‚îú‚îÄ‚îÄ run-local.sh            # Script de inicializa√ß√£o simplificada
‚îú‚îÄ‚îÄ DEPLOY_AWS.md           # Instru√ß√µes para deploy na AWS
‚îú‚îÄ‚îÄ pyproject.toml          # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ configs/                # Configura√ß√µes de ambiente
‚îî‚îÄ‚îÄ src/                    # C√≥digo-fonte
    ‚îú‚îÄ‚îÄ api/                # API de recomenda√ß√£o
    ‚îú‚îÄ‚îÄ data/               # Manipula√ß√£o de dados
    ‚îú‚îÄ‚îÄ evaluation/         # M√©tricas e avalia√ß√£o
    ‚îú‚îÄ‚îÄ features/           # Feature engineering
    ‚îú‚îÄ‚îÄ predict/            # Pipeline de predi√ß√£o
    ‚îú‚îÄ‚îÄ recommendation_model/# Modelos de recomenda√ß√£o
    ‚îú‚îÄ‚îÄ storage/            # Abstra√ß√£o de armazenamento
    ‚îî‚îÄ‚îÄ train/              # Pipeline de treinamento
```

## Endpoints e Monitoramento

### Endpoints da API

- **`GET /health`**: Verifica a integridade da API.
- **`GET /info`**: Retorna informa√ß√µes sobre o modelo e o ambiente.
- **`POST /predict`**: Gera recomenda√ß√µes para um usu√°rio.  

  **Exemplo de requisi√ß√£o:**

  ```json
  {
    "userId": "4b3c2c5c0edaf59137e164ef6f7d88f94d66d0890d56020de1ca6afd55b4f297",
    "max_results": 5,
    "minScore": 0.3
  }
  ```

### Monitoramento de Performance

A resposta da API inclui m√©tricas detalhadas, como:
  ```json
      {
        "processing_time_ms": 123.45,
        "timing_details": {
          "dependencies": 0.01,
          "prediction": 0.12,
          "formatting": 0.01,
          "total_ms": 123.45
        }
      }
  ```
Essas informa√ß√µes auxiliam na identifica√ß√£o e resolu√ß√£o de gargalos.

---



# Setups e Rodagens em Containers


## ‚ú® Principais Caracter√≠sticas

- **API FastAPI:** Interface de alta performance para recomenda√ß√µes em tempo real
- **MLflow Integration:** Registro e versionamento de modelos com tracking de m√©tricas
- **Containeriza√ß√£o:** Deploy simplificado via Docker
- **Otimiza√ß√µes de Performance:** Caching, profiling e redu√ß√£o de processamento redundante
- **Suporte a Ambientes:** Configura√ß√µes para desenvolvimento local e produ√ß√£o
- **Suporte a Cold Start:** Tratamento para usu√°rios novos ou com pouca informa√ß√£o
- **Portabilidade AWS:** Pronto para deploy em AWS ECS Fargate

## üöÄ Inicializa√ß√£o R√°pida

### Pr√©-requisitos

- Docker
- Docker Compose
- Bash (para o script de inicializa√ß√£o)

### Executar Localmente (Desenvolvimento)

```bash
# Tornar o script execut√°vel
chmod +x run-local.sh

# Iniciar todos os servi√ßos em modo desenvolvimento (API + MLflow)
./run-local.sh

# Para reconstruir as imagens (ap√≥s altera√ß√µes no c√≥digo)
./run-local.sh dev full rebuild

# Para ver logs ap√≥s inicializa√ß√£o
./run-local.sh dev full logs
```

### Executar em Modo Produ√ß√£o (Usando MLflow remoto)

```bash
# Configurar credenciais AWS para acesso ao S3 (opcional)
export AWS_ACCESS_KEY_ID="sua-chave"  
export AWS_SECRET_ACCESS_KEY="seu-secret"

# Iniciar apenas a API em modo produ√ß√£o
./run-local.sh prod api
```

### Op√ß√µes de Inicializa√ß√£o

```bash
# Ver ajuda e todas as op√ß√µes dispon√≠veis
./run-local.sh help

# Exemplos comuns:
./run-local.sh dev api      # Apenas API em modo desenvolvimento
./run-local.sh dev mlflow   # Apenas MLflow local
./run-local.sh prod api     # API em modo produ√ß√£o (MLflow remoto)
```



## üîç Endpoints da API

- **`GET /health`**: Verifica a sa√∫de da API
- **`GET /info`**: Informa√ß√µes sobre o modelo e ambiente
- **`POST /predict`**: Gera recomenda√ß√µes para um usu√°rio

### Exemplo de requisi√ß√£o para `/predict`:

```json
{
  "userId": "4b3c2c5c0edaf59137e164ef6f7d88f94d66d0890d56020de1ca6afd55b4f297",
  "max_results": 5,
  "minScore": 0.3
}
```

## üìä Monitoramento de Performance

A API agora inclui m√©tricas detalhadas de performance para ajudar a identificar e resolver gargalos. Ao fazer uma chamada para `/predict`, a resposta incluir√°:

```json
{
  "processing_time_ms": 123.45,
  "timing_details": {
    "dependencies": 0.01,
    "prediction": 0.12,
    "formatting": 0.01,
    "total_ms": 123.45
  }
}
```

## üê≥ Configura√ß√£o Docker

O projeto utiliza dois arquivos principais:

- **`Dockerfile`**: Container otimizado para produ√ß√£o
- **`docker-compose.yml`**: Configura√ß√£o de ambiente local

## üåê Configura√ß√£o de Ambientes

O sistema suporta dois ambientes principais:

### 1. Desenvolvimento (`dev`)

- MLflow local para experimentos
- Armazenamento local de dados
- Taxa de amostragem reduzida para testes r√°pidos

### 2. Produ√ß√£o (`prod`)

- MLflow remoto para registro de modelos
- Armazenamento S3 para dados e artefatos
- Taxa de amostragem completa para melhor performance


## üö¢ Deploy na AWS

Para fazer o deploy do sistema na AWS ECS usando Fargate:

1. Siga as instru√ß√µes detalhadas em `DEPLOY_AWS.md`
2. Automatize o processo com o script de deploy inclu√≠do



### Contribuindo

Para colaborar com o projeto:

1. Clone o reposit√≥rio.
2. Instale as depend√™ncias com `uv pip install -e .`.
3. Crie uma nova branch para suas altera√ß√µes.
4. Envie um Pull Request com uma descri√ß√£o clara das mudan√ßas.

---

### Notas

- O script `run-local.sh` deve ser executado a partir da raiz do projeto.
- Certifique-se de manter a consist√™ncia nas configura√ß√µes de ambiente e documenta√ß√£o entre os m√≥dulos.

---


## Refer√™ncias

- [LightGBM Documentation](https://lightgbm.readthedocs.io/)  
- [Lambdarank Paper](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf)  
- [MLflow Model Registry](https://mlflow.org/docs/latest/model-registry.html)  
- [Pandas Documentation](https://pandas.pydata.org/docs/)  
- [FastAPI Documentation](https://fastapi.tiangolo.com/)

